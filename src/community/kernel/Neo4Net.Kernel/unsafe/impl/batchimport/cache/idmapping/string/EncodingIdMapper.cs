using System;
using System.Diagnostics;
using System.Threading;

/*
 * Copyright © 2018-2020 "Neo4Net,"
 * Team NeoN [http://neo4net.com]. All Rights Reserved.
 *
 * This file is part of Neo4Net.
 *
 * Neo4Net is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
namespace Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.@string
{
	using LongIterator = org.eclipse.collections.api.iterator.LongIterator;
	using ImmutableEmptyLongIterator = org.eclipse.collections.impl.iterator.ImmutableEmptyLongIterator;


	using PrimitiveLongCollections = Neo4Net.Collections.PrimitiveLongCollections;
	using Neo4Net.Functions;
	using ProgressListener = Neo4Net.Helpers.progress.ProgressListener;
	using CompareType = Neo4Net.@unsafe.Impl.Batchimport.Utils.CompareType;
	using Comparator = Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.@string.ParallelSort.Comparator;
	using Collector = Neo4Net.@unsafe.Impl.Batchimport.input.Collector;
	using Group = Neo4Net.@unsafe.Impl.Batchimport.input.Group;
	using Groups = Neo4Net.@unsafe.Impl.Batchimport.input.Groups;
	using InputException = Neo4Net.@unsafe.Impl.Batchimport.input.InputException;

//JAVA TO C# CONVERTER TODO TASK: This Java 'import static' statement cannot be converted to C#:
//	import static Math.max;
//JAVA TO C# CONVERTER TODO TASK: This Java 'import static' statement cannot be converted to C#:
//	import static Math.min;
//JAVA TO C# CONVERTER TODO TASK: This Java 'import static' statement cannot be converted to C#:
//	import static Math.toIntExact;
//JAVA TO C# CONVERTER TODO TASK: This Java 'import static' statement cannot be converted to C#:
//	import static org.neo4j.@unsafe.impl.batchimport.Utils.unsignedCompare;
//JAVA TO C# CONVERTER TODO TASK: This Java 'import static' statement cannot be converted to C#:
//	import static org.neo4j.@unsafe.impl.batchimport.Utils.unsignedDifference;
//JAVA TO C# CONVERTER TODO TASK: This Java 'import static' statement cannot be converted to C#:
//	import static org.neo4j.@unsafe.impl.batchimport.cache.idmapping.@string.ParallelSort.DEFAULT;

	/// <summary>
	/// Maps arbitrary values to long ids. The values can be <seealso cref="put(object, long, Group) added"/> in any order,
	/// but <seealso cref="needsPreparation() needs"/> <seealso cref="prepare(LongFunction, Collector, ProgressListener) preparation"/>
	/// 
	/// in order to <seealso cref="get(object, Group) get"/> ids back later.
	/// 
	/// In the <seealso cref="prepare(LongFunction, Collector, ProgressListener) preparation phase"/> the added entries are
	/// sorted according to a number representation of each input value and <seealso cref="get(object, Group)"/> does simple
	/// binary search to find the correct one.
	/// 
	/// The implementation is space-efficient, much more so than using, say, a <seealso cref="System.Collections.Hashtable"/>.
	/// 
	/// Terminology... there's a lot going on in here, and to help you understand the code here's a list
	/// of terms used in comments and variable names and some description what each generally means
	/// (also applies to <seealso cref="ParallelSort"/> btw):
	/// - input id:
	///       An id coming from the user that is associated with a neo4j id by calling <seealso cref="put(object, long, Group)"/>.
	///       the first argument is the id that the user specified, the second is the neo4j id that user id will
	///       be associated with.
	/// - encoder:
	///       Encodes an input id into an internal, more space efficient representation (a {@code long}) of that input id.
	/// - eId:
	///       The internal representation of an input id, generated by an encoder.
	/// - data cache:
	///       An array of eIds. eIds are added in the order of neo4j ids, i.e. in the order in which they are put.
	/// - tracker cache:
	///       An array where every array item is a pointer to an index into the data cache it's set to track.
	///       After the data cache has been filled the eIds are sorted. This is done by _not_ sorting the data cache,
	///       but instead sorting the tracker cache as a proxy to its data cache. The reason it's done like this
	///       is that id spaces (<seealso cref="Group"/>) are kept as data cache ranges, since all ids for any given id space
	///       must be added together before adding any id for another id space.
	/// - collision:
	///       Since eId has potentially fewer bits than an input id there's a chance multiple different (or equal)
	///       input ids will be encoded into the same eId. These are called collisions.
	/// </summary>
	public class EncodingIdMapper : IdMapper
	{
		 public interface Monitor
		 {
			  /// <param name="count"> Number of eIds that have been marked as collisions. </param>
			  void NumberOfCollisions( long count );
		 }

		 public static readonly Monitor NoMonitor = count =>
		 { // Do nothing.
		 };

		 // Bit in encoded String --> long values that marks that the particular item has a collision,
		 // i.e. that there's at least one other string that encodes into the same long value.
		 // This bit is the least significant in the most significant byte of the encoded values,
		 // where the 7 most significant bits in that byte denotes length of original string.
		 // See StringEncoder.
		 private static readonly LongBitsManipulator _collisionBit = new LongBitsManipulator( 56, 1 );
		 private const int DEFAULT_CACHE_CHUNK_SIZE = 1_000_000; // 8MB a piece
		 private const int COLLISION_ENTRY_SIZE = 5 + 6;
		 // Using 0 as gap value, i.e. value for a node not having an id, i.e. not present in dataCache is safe
		 // because the current set of Encoder implementations will always set some amount of bits higher up in
		 // the long value representing the length of the id.
		 private const long GAP_VALUE = 0;

		 private readonly IFactory<Radix> _radixFactory;
		 private readonly NumberArrayFactory _cacheFactory;
		 private readonly TrackerFactory _trackerFactory;
		 // Encoded values added in #put, in the order in which they are put. Indexes in the array are the actual node ids,
		 // values are the encoded versions of the input ids.
		 private readonly LongArray _dataCache;
		 private readonly GroupCache _groupCache;
		 private readonly HighestId _candidateHighestSetIndex = new HighestId( -1 );
		 private long _highestSetIndex;

		 // Ordering information about values in dataCache; the ordering of values in dataCache remains unchanged.
		 // in prepare() this array is populated and changed along with how dataCache items "move around" so that
		 // they end up sorted. Again, dataCache remains unchanged, only the ordering information is kept here.
		 // Each index in trackerCache points to a dataCache index, where the value in dataCache contains the
		 // encoded input id, used to match against the input id that is looked up during binary search.
		 private Tracker _trackerCache;
		 private readonly Encoder _encoder;
		 private readonly Radix _radix;
		 private readonly int _processorsForParallelWork;
		 private readonly Comparator _comparator;

		 private ByteArray _collisionNodeIdCache;
		 // These 3 caches below are needed only during duplicate input id detection, but referenced here so
		 // that the memory visitor can see them when they are active.
		 private Tracker _collisionTrackerCache;

		 private bool _readyForUse;
		 private long[][] _sortBuckets;

		 private readonly Monitor _monitor;
		 private readonly Groups _groups;

		 private long _numberOfCollisions;
		 private readonly System.Func<long, CollisionValues> _collisionValuesFactory;
		 private CollisionValues _collisionValues;

		 public EncodingIdMapper( NumberArrayFactory cacheFactory, Encoder encoder, IFactory<Radix> radixFactory, Monitor monitor, TrackerFactory trackerFactory, Groups groups, System.Func<long, CollisionValues> collisionValuesFactory ) : this( cacheFactory, encoder, radixFactory, monitor, trackerFactory, groups, collisionValuesFactory, DEFAULT_CACHE_CHUNK_SIZE, Runtime.Runtime.availableProcessors() - 1, DEFAULT )
		 {
		 }

		 internal EncodingIdMapper( NumberArrayFactory cacheFactory, Encoder encoder, IFactory<Radix> radixFactory, Monitor monitor, TrackerFactory trackerFactory, Groups groups, System.Func<long, CollisionValues> collisionValuesFactory, int chunkSize, int processorsForParallelWork, Comparator comparator )
		 {
			  this._radixFactory = radixFactory;
			  this._monitor = monitor;
			  this._cacheFactory = cacheFactory;
			  this._trackerFactory = trackerFactory;
			  this._collisionValuesFactory = collisionValuesFactory;
			  this._comparator = comparator;
			  this._processorsForParallelWork = max( processorsForParallelWork, 1 );
			  this._dataCache = cacheFactory.NewDynamicLongArray( chunkSize, GAP_VALUE );
			  this._groupCache = GroupCache.select( cacheFactory, chunkSize, groups.Size() );
			  this._groups = groups;
			  this._encoder = encoder;
			  this._radix = radixFactory.NewInstance();
		 }

		 /// <summary>
		 /// Returns the data index (i.e. node id) if found, or {@code -1} if not found.
		 /// </summary>
		 public override long Get( object inputId, Group group )
		 {
			  Debug.Assert( _readyForUse );
			  return BinarySearch( inputId, group.Id() );
		 }

		 public override void Put( object inputId, long nodeId, Group group )
		 {
			  // Encode and add the input id
			  long eId = Encode( inputId );
			  _dataCache.set( nodeId, eId );
			  _groupCache.set( nodeId, group.Id() );
			  _candidateHighestSetIndex.offer( nodeId );
		 }

		 private long Encode( object inputId )
		 {
			  long eId = _encoder.encode( inputId );
			  if ( eId == GAP_VALUE )
			  {
					throw new System.InvalidOperationException( "Encoder " + _encoder + " returned an illegal encoded value " + GAP_VALUE );
			  }
			  return eId;
		 }

		 public override bool NeedsPreparation()
		 {
			  return true;
		 }

		 /// <summary>
		 /// There's an assumption that the progress listener supplied here can support multiple calls
		 /// to started/done, and that it knows about what stages the processor preparing goes through, namely:
		 /// <ol>
		 /// <li>Split by radix</li>
		 /// <li>Sorting</li>
		 /// <li>Collision detection</li>
		 /// <li>(potentially) Collision resolving</li>
		 /// </ol>
		 /// </summary>
		 public override void Prepare( System.Func<long, object> inputIdLookup, Collector collector, ProgressListener progress )
		 {
			  _highestSetIndex = _candidateHighestSetIndex.get();
			  UpdateRadix( _dataCache, _radix, _highestSetIndex );
			  _trackerCache = _trackerFactory.create( _cacheFactory, _highestSetIndex + 1 );

			  try
			  {
					_sortBuckets = ( new ParallelSort( _radix, _dataCache, _highestSetIndex, _trackerCache, _processorsForParallelWork, progress, _comparator ) ).run();

					long pessimisticNumberOfCollisions = DetectAndMarkCollisions( progress );
					if ( pessimisticNumberOfCollisions > 0 )
					{
						 BuildCollisionInfo( inputIdLookup, pessimisticNumberOfCollisions, collector, progress );
					}
			  }
			  catch ( InterruptedException )
			  {
					Thread.interrupted();
					throw new Exception( "Got interrupted while preparing the index. Throwing this exception " + "onwards will cause a chain reaction which will cause a panic in the whole import, " + "so mission accomplished" );
			  }
			  _readyForUse = true;
		 }

		 private static void UpdateRadix( LongArray values, Radix radix, long highestSetIndex )
		 {
			  for ( long dataIndex = 0; dataIndex <= highestSetIndex; dataIndex++ )
			  {
					radix.RegisterRadixOf( values.Get( dataIndex ) );
			  }
		 }

		 private int RadixOf( long value )
		 {
			  return _radix.calculator().radixOf(value);
		 }

		 private long BinarySearch( object inputId, int groupId )
		 {
			  long low = 0;
			  long high = _highestSetIndex;
			  long x = Encode( inputId );
			  int rIndex = RadixOf( x );
			  for ( int k = 0; k < _sortBuckets.Length; k++ )
			  {
					if ( rIndex <= _sortBuckets[k][0] ) //bucketRange[k] > rIndex )
					{
						 low = _sortBuckets[k][1];
						 high = ( k == _sortBuckets.Length - 1 ) ? _highestSetIndex : _sortBuckets[k + 1][1];
						 break;
					}
			  }

			  long returnVal = BinarySearch( x, inputId, low, high, groupId );
			  if ( returnVal == Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND )
			  {
					low = 0;
					high = _highestSetIndex;
					returnVal = BinarySearch( x, inputId, low, high, groupId );
			  }
			  return returnVal;
		 }

		 private static long setCollision( long eId )
		 {
			  return _collisionBit.set( eId, 1, 1 );
		 }

		 internal static long ClearCollision( long eId )
		 {
			  return _collisionBit.clear( eId, 1, false );
		 }

		 private static bool IsCollision( long eId )
		 {
			  return _collisionBit.get( eId, 1 ) != 0;
		 }

		 private class DetectWorker : ThreadStart
		 {
			 private readonly EncodingIdMapper _outerInstance;

			  internal readonly long FromInclusive;
			  internal readonly long ToExclusive;
			  internal readonly bool Last;
			  internal readonly ProgressListener Progress;

			  internal int NumberOfCollisions;
			  internal int LocalProgress;

			  internal DetectWorker( EncodingIdMapper outerInstance, long fromInclusive, long toExclusive, bool last, ProgressListener progress )
			  {
				  this._outerInstance = outerInstance;
					this.FromInclusive = fromInclusive;
					this.ToExclusive = toExclusive;
					this.Last = last;
					this.Progress = progress;
			  }

			  public override void Run()
			  {
					SameGroupDetector sameGroupDetector = new SameGroupDetector();

					// In all chunks except the last this chunk also takes care of the detection in the seam,
					// but for the last one there's no seam at the end.
					long end = Last ? ToExclusive - 1 : ToExclusive;

					for ( long i = FromInclusive; i < end; i++ )
					{
						 Detect( sameGroupDetector, i );
						 if ( ++LocalProgress == 1000 )
						 {
							  Progress.add( LocalProgress );
							  LocalProgress = 0;
						 }
					}
					Progress.add( LocalProgress );
			  }

			  internal virtual void Detect( SameGroupDetector sameGroupDetector, long i )
			  {
					long dataIndexA = outerInstance.trackerCache.Get( i );
					long dataIndexB = outerInstance.trackerCache.Get( i + 1 );
					if ( dataIndexA == Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND || dataIndexB == Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND )
					{
						 sameGroupDetector.Reset();
						 return;
					}

					long eIdA = ClearCollision( outerInstance.dataCache.Get( dataIndexA ) );
					long eIdB = ClearCollision( outerInstance.dataCache.Get( dataIndexB ) );
					if ( eIdA == GAP_VALUE || eIdB == GAP_VALUE )
					{
						 sameGroupDetector.Reset();
						 return;
					}

					switch ( unsignedDifference( eIdA, eIdB ) )
					{
					case GT:
						throw new System.InvalidOperationException( "Unsorted data, a > b Failure:[" + i + "] " + eIdA.ToString( "x" ) + " > " + eIdB.ToString( "x" ) + " | " + outerInstance.radixOf( eIdA ) + ":" + outerInstance.radixOf( eIdB ) );
					case EQ:
						 // Here we have two equal encoded values. First let's check if they are in the same id space.
						 long collision = sameGroupDetector.CollisionWithinSameGroup( dataIndexA, outerInstance.groupOf( dataIndexA ), dataIndexB, outerInstance.groupOf( dataIndexB ) );

						 if ( dataIndexA > dataIndexB )
						 {
							  // Swap so that lower tracker index means lower data index. TODO Why do we do this?
							  outerInstance.trackerCache.Swap( i, i + 1 );
						 }

						 if ( collision != Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND )
						 {
							  if ( outerInstance.markAsCollision( collision ) )
							  {
									NumberOfCollisions++;
							  }
							  if ( outerInstance.markAsCollision( dataIndexB ) )
							  {
									NumberOfCollisions++;
							  }
						 }
						 break;
					default:
						 sameGroupDetector.Reset();
					 break;
					}
			  }
		 }

		 /// <summary>
		 /// There are two types of collisions:
		 /// - actual: collisions coming from equal input value. These might however not impose
		 ///   keeping original input value since the colliding values might be for separate id groups,
		 ///   just as long as there's at most one per id space.
		 /// - accidental: collisions coming from different input values that happens to coerce into
		 ///   the same encoded value internally.
		 /// 
		 /// For any encoded value there might be a mix of actual and accidental collisions. As long as there's
		 /// only one such value (accidental or actual) per id space the original input id doesn't need to be kept.
		 /// For scenarios where there are multiple per for any given id space:
		 /// - actual: there are two equal input values in the same id space
		 ///     ==> fail, not allowed
		 /// - accidental: there are two different input values coerced into the same encoded value
		 ///   in the same id space
		 ///     ==> original input values needs to be kept
		 /// </summary>
		 /// <returns> rough number of collisions. The number can be slightly more than it actually is due to benign
		 /// races between detector workers. This is not a problem though, this value serves as a pessimistic value
		 /// for allocating arrays to hold collision data to later sort and use to discover duplicates. </returns>
		 private long DetectAndMarkCollisions( ProgressListener progress )
		 {
			  progress.Started( "DETECT" );
			  long totalCount = _highestSetIndex + 1;

			  Workers<DetectWorker> workers = new Workers<DetectWorker>( "DETECT" );
			  int processors = _processorsForParallelWork;
			  long stride = totalCount / _processorsForParallelWork;
			  if ( stride < 10 )
			  {
					// Multi-threading would be overhead
					processors = 1;
					stride = totalCount;
			  }
			  long fromInclusive = 0;
			  long toExclusive = 0;
			  for ( int i = 0; i < processors; i++ )
			  {
					bool last = i == processors - 1;
					fromInclusive = toExclusive;
					toExclusive = last ? totalCount : toExclusive + stride;
					workers.Start( new DetectWorker( this, fromInclusive, toExclusive, last, progress ) );
			  }
			  workers.AwaitAndThrowOnErrorStrict();

			  long numberOfCollisions = 0;
			  foreach ( DetectWorker detectWorker in workers )
			  {
					numberOfCollisions += detectWorker.NumberOfCollisions;
			  }

			  progress.Done();
			  if ( numberOfCollisions > int.MaxValue )
			  {
					throw new InputException( "Too many collisions: " + numberOfCollisions );
			  }

			  int intNumberOfCollisions = toIntExact( numberOfCollisions );
			  _monitor.numberOfCollisions( intNumberOfCollisions );
			  return intNumberOfCollisions;
		 }

		 /// <returns> {@code true} if marked as collision in this call, {@code false} if it was already marked as collision. </returns>
		 private bool MarkAsCollision( long nodeId )
		 {
			  long eId = _dataCache.get( nodeId );
			  bool isAlreadyMarked = IsCollision( eId );
			  if ( isAlreadyMarked )
			  {
					return false;
			  }

			  _dataCache.set( nodeId, setCollision( eId ) );
			  return true;
		 }

		 private void UnmarkAsCollision( long dataIndex )
		 {
			  long eId = _dataCache.get( dataIndex );
			  bool isMarked = IsCollision( eId );
			  if ( isMarked )
			  {
					_dataCache.set( dataIndex, ClearCollision( eId ) );
			  }
		 }

//JAVA TO C# CONVERTER WARNING: Method 'throws' clauses are not available in C#:
//ORIGINAL LINE: private void buildCollisionInfo(System.Func<long, Object> inputIdLookup, long pessimisticNumberOfCollisions, org.neo4j.unsafe.impl.batchimport.input.Collector collector, org.neo4j.helpers.progress.ProgressListener progress) throws InterruptedException
		 private void BuildCollisionInfo( System.Func<long, object> inputIdLookup, long pessimisticNumberOfCollisions, Collector collector, ProgressListener progress )
		 {
			  progress.Started( "RESOLVE (~" + pessimisticNumberOfCollisions + " collisions)" );
			  Radix radix = _radixFactory.newInstance();
			  _collisionNodeIdCache = _cacheFactory.newByteArray( pessimisticNumberOfCollisions, new sbyte[COLLISION_ENTRY_SIZE] );
			  _collisionTrackerCache = _trackerFactory.create( _cacheFactory, pessimisticNumberOfCollisions );
			  _collisionValues = _collisionValuesFactory.apply( pessimisticNumberOfCollisions );
			  for ( long nodeId = 0; nodeId <= _highestSetIndex; nodeId++ )
			  {
					long eId = _dataCache.get( nodeId );
					if ( IsCollision( eId ) )
					{
						 // Store this collision input id for matching later in get()
						 long collisionIndex = _numberOfCollisions++;
						 object id = inputIdLookup( nodeId );
						 long eIdFromInputId = Encode( id );
						 long eIdWithoutCollisionBit = ClearCollision( eId );
						 Debug.Assert( eIdFromInputId == eIdWithoutCollisionBit, format( "Encoding mismatch during building of " + "collision info. input id %s (a %s) marked as collision where this id was encoded into " + "%d when put, but was now encoded into %d", id, id.GetType().Name, eIdWithoutCollisionBit, eIdFromInputId ) );
						 long offset = _collisionValues.add( id );
						 _collisionNodeIdCache.set5ByteLong( collisionIndex, 0, nodeId );
						 _collisionNodeIdCache.set6ByteLong( collisionIndex, 5, offset );

						 // The base of our sorting this time is going to be node id, so register that in the radix
						 radix.RegisterRadixOf( eIdWithoutCollisionBit );
					}
					progress.Add( 1 );
			  }
			  progress.Done();

			  // Detect input id duplicates within the same group, with source information, line number and the works
			  DetectDuplicateInputIds( radix, collector, progress );

			  // We won't be needing these anymore
			  _collisionTrackerCache.close();
			  _collisionTrackerCache = null;
		 }

//JAVA TO C# CONVERTER WARNING: Method 'throws' clauses are not available in C#:
//ORIGINAL LINE: private void detectDuplicateInputIds(Radix radix, org.neo4j.unsafe.impl.batchimport.input.Collector collector, org.neo4j.helpers.progress.ProgressListener progress) throws InterruptedException
		 private void DetectDuplicateInputIds( Radix radix, Collector collector, ProgressListener progress )
		 {
			  // We do this collision sort using ParallelSort which has the data cache and the tracker cache,
			  // the tracker cache gets sorted, data cache stays intact. In the collision data case we actually
			  // have one more layer in here so we have tracker cache pointing to collisionNodeIdCache
			  // pointing to dataCache. This can be done using the ParallelSort.Comparator abstraction.
			  //
			  // The Comparator below takes into account dataIndex for each eId its comparing so that an extra
			  // comparison based on dataIndex is done if it's comparing two equal eIds. We do this so that
			  // stretches of multiple equal eIds are sorted by dataIndex (i.e. node id) order,
			  // to be able to write an efficient duplication scanning below and to have deterministic duplication reporting.
			  Comparator duplicateComparator = new ComparatorAnonymousInnerClass( this );

			  ( new ParallelSort( radix, As5ByteLongArray( _collisionNodeIdCache ), _numberOfCollisions - 1, _collisionTrackerCache, _processorsForParallelWork, progress, duplicateComparator ) ).run();

			  // Here we have a populated C
			  // We want to detect duplicate input ids within it
			  long previousEid = 0;
			  int previousGroupId = -1;
			  SameInputIdDetector detector = new SameInputIdDetector();
			  progress.Started( "DEDUPLICATE" );
			  for ( int i = 0; i < _numberOfCollisions; i++ )
			  {
					long collisionIndex = _collisionTrackerCache.get( i );
					long nodeId = _collisionNodeIdCache.get5ByteLong( collisionIndex, 0 );
					long offset = _collisionNodeIdCache.get6ByteLong( collisionIndex, 5 );
					long eid = _dataCache.get( nodeId );
					int groupId = GroupOf( nodeId );
					// collisions of same eId AND groupId are always together
					bool same = eid == previousEid && previousGroupId == groupId;
					if ( !same )
					{
						 detector.Clear();
					}

					// Potential duplicate
					object inputId = _collisionValues.get( offset );
					long nonDuplicateNodeId = detector.Add( nodeId, inputId );
					if ( nonDuplicateNodeId != -1 )
					{ // Duplicate
						 collector.CollectDuplicateNode( inputId, nodeId, _groups.get( groupId ).name() );
						 _trackerCache.markAsDuplicate( nodeId );
						 UnmarkAsCollision( nonDuplicateNodeId );
					}

					previousEid = eid;
					previousGroupId = groupId;
					progress.Add( 1 );
			  }
			  progress.Done();
		 }

		 private class ComparatorAnonymousInnerClass : System.Collections.IComparer
		 {
			 private readonly EncodingIdMapper _outerInstance;

			 public ComparatorAnonymousInnerClass( EncodingIdMapper outerInstance )
			 {
				 this.outerInstance = outerInstance;
			 }

			 public bool lt( long left, long pivot )
			 {
				  long leftEId = _outerInstance.dataCache.get( left );
				  long pivotEId = _outerInstance.dataCache.get( pivot );
				  if ( _outerInstance.comparator.lt( leftEId, pivotEId ) )
				  {
						return true;
				  }
				  if ( leftEId == pivotEId )
				  {
						return left < pivot;
				  }
				  return false;
			 }

			 public bool ge( long right, long pivot )
			 {
				  long rightEId = _outerInstance.dataCache.get( right );
				  long pivotEId = _outerInstance.dataCache.get( pivot );
				  if ( _outerInstance.comparator.ge( rightEId, pivotEId ) )
				  {
						return rightEId != pivotEId || right > pivot;
				  }
				  return false;
			 }

			 public long dataValue( long nodeId )
			 {
				  return _outerInstance.dataCache.get( nodeId );
			 }
		 }

		 private LongArray As5ByteLongArray( ByteArray byteArray )
		 {
			  return new LongArrayAnonymousInnerClass( this, byteArray );
		 }

		 private class LongArrayAnonymousInnerClass : LongArray
		 {
			 private readonly EncodingIdMapper _outerInstance;

			 private ByteArray _byteArray;

			 public LongArrayAnonymousInnerClass( EncodingIdMapper outerInstance, ByteArray byteArray )
			 {
				 this.outerInstance = outerInstance;
				 this._byteArray = byteArray;
			 }

			 public void acceptMemoryStatsVisitor( MemoryStatsVisitor visitor )
			 {
				  _byteArray.acceptMemoryStatsVisitor( visitor );
			 }

			 public long length()
			 {
				  return _byteArray.length();
			 }

			 public void close()
			 {
				  _byteArray.close();
			 }

			 public void clear()
			 {
				  _byteArray.clear();
			 }

			 public LongArray at( long index )
			 {
				  return null;
			 }

			 public void set( long index, long value )
			 {
				  throw new System.NotSupportedException();
			 }

			 public long get( long index )
			 {
				  return _byteArray.get5ByteLong( index, 0 );
			 }
		 }

		 private class SameInputIdDetector
		 {
			  internal long[] NodeIdArray = new long[10]; // grows on demand
			  internal object[] InputIdArray = new object[10]; // grows on demand
			  internal int Cursor;

			  internal virtual long Add( long nodeId, object inputId )
			  {
					for ( int i = 0; i < Cursor; i++ )
					{
						 if ( InputIdArray[i].Equals( inputId ) )
						 {
							  return NodeIdArray[i];
						 }
					}

					if ( Cursor == InputIdArray.Length )
					{
						 InputIdArray = Arrays.copyOf( InputIdArray, Cursor * 2 );
						 NodeIdArray = Arrays.copyOf( NodeIdArray, Cursor * 2 );
					}
					InputIdArray[Cursor] = inputId;
					NodeIdArray[Cursor] = nodeId;
					Cursor++;
					return -1;
			  }

			  internal virtual void Clear()
			  {
					Cursor = 0;
			  }
		 }

		 private int GroupOf( long dataIndex )
		 {
			  return _groupCache.get( dataIndex );
		 }

		 private long BinarySearch( long x, object inputId, long low, long high, int groupId )
		 {
			  while ( low <= high )
			  {
					long mid = low + ( high - low ) / 2; //(low + high) / 2;
					long dataIndex = _trackerCache.get( mid );
					if ( dataIndex == Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND )
					{
						 return Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND;
					}
					long midValue = _dataCache.get( dataIndex );
					switch ( unsignedDifference( ClearCollision( midValue ), x ) )
					{
					case EQ:
						 // We found the value we were looking for. Question now is whether or not it's the only
						 // of its kind. Not all values that there are duplicates of are considered collisions,
						 // read more in detectAndMarkCollisions(). So regardless we need to check previous/next
						 // if they are the same value.
						 bool leftEq = mid > 0 && unsignedCompare( x, DataValue( mid - 1 ), CompareType.EQ );
						 bool rightEq = mid < _highestSetIndex && unsignedCompare( x, DataValue( mid + 1 ), CompareType.EQ );
						 if ( leftEq || rightEq )
						 { // OK so there are actually multiple equal data values here, we need to go through them all
							  // to be sure we find the correct one.
							  return FindFromEIdRange( leftEq ? mid - 1 : mid, rightEq ? mid + 1 : mid, midValue, inputId, x, groupId );
						 }
						 // This is the only value here, let's do a simple comparison with correct group id and return
						 return GroupOf( dataIndex ) == groupId ? dataIndex : Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND;
					case LT:
						 low = mid + 1;
						 break;
					default:
						 high = mid - 1;
						 break;
					}
			  }
			  return Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND;
		 }

		 private long DataValue( long index )
		 {
			  return ClearCollision( _dataCache.get( _trackerCache.get( index ) ) );
		 }

		 private long FindCollisionIndex( long value )
		 {
			  // can't be done on unsorted data
			  long low = 0;
			  long high = _numberOfCollisions - 1;
			  while ( low <= high )
			  {
					long mid = ( low + high ) / 2;
					long midValue = _collisionNodeIdCache.get5ByteLong( mid, 0 );
					switch ( unsignedDifference( midValue, value ) )
					{
					case EQ:
						return mid;
					case LT:
						 low = mid + 1;
						 break;
					default:
						 high = mid - 1;
						 break;
					}
			  }
			  return Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND;
		 }

		 private long FindFromEIdRange( long fromIndex, long toIndex, long val, object inputId, long x, int groupId )
		 {
			  val = ClearCollision( val );
			  Debug.Assert( val == x );

			  while ( fromIndex > 0 && unsignedCompare( val, DataValue( fromIndex - 1 ), CompareType.EQ ) )
			  {
					fromIndex--;
			  }
			  while ( toIndex < _highestSetIndex && unsignedCompare( val, DataValue( toIndex + 1 ), CompareType.EQ ) )
			  {
					toIndex++;
			  }

			  return FindFromEIdRange( fromIndex, toIndex, groupId, inputId );
		 }

		 private long FindFromEIdRange( long fromIndex, long toIndex, int groupId, object inputId )
		 {
			  long lowestFound = Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND; // lowest data index means "first put"
			  for ( long index = fromIndex; index <= toIndex; index++ )
			  {
					long nodeId = _trackerCache.get( index );
					int group = GroupOf( nodeId );
					if ( groupId == group )
					{
						 long eId = _dataCache.get( nodeId );
						 if ( IsCollision( eId ) )
						 {
							  if ( !_trackerCache.isMarkedAsDuplicate( nodeId ) )
							  { // We found a data value for our group, but there are collisions within this group.
									// We need to consult the collision cache and original input id
									long collisionIndex = FindCollisionIndex( nodeId );
									long offset = _collisionNodeIdCache.get6ByteLong( collisionIndex, 5 );
									object value = _collisionValues.get( offset );
									if ( inputId.Equals( value ) )
									{
										 // :)
										 lowestFound = lowestFound == Neo4Net.@unsafe.Impl.Batchimport.cache.idmapping.IdMapper_Fields.ID_NOT_FOUND ? nodeId : min( lowestFound, nodeId );
										 // continue checking so that we can find the lowest one. It's not up to us here to
										 // consider multiple equal ids in this group an error or not. That should have been
										 // decided in #prepare.
									}
							  }
						 }
						 else
						 { // We found a data value that is alone in its group. Just return it
							  // :D
							  lowestFound = nodeId;

							  // We don't need to look no further because this value wasn't a collision,
							  // i.e. there are more like it for this group
							  break;
						 }
					}
			  }
			  return lowestFound;
		 }

		 public override void AcceptMemoryStatsVisitor( MemoryStatsVisitor visitor )
		 {
			  NullSafeAcceptMemoryStatsVisitor( visitor, _dataCache );
			  NullSafeAcceptMemoryStatsVisitor( visitor, _trackerCache );
			  NullSafeAcceptMemoryStatsVisitor( visitor, _collisionTrackerCache );
			  NullSafeAcceptMemoryStatsVisitor( visitor, _collisionNodeIdCache );
			  NullSafeAcceptMemoryStatsVisitor( visitor, _collisionValues );
		 }

		 private void NullSafeAcceptMemoryStatsVisitor( MemoryStatsVisitor visitor, MemoryStatsVisitor_Visitable mem )
		 {
			  if ( mem != null )
			  {
					mem.AcceptMemoryStatsVisitor( visitor );
			  }
		 }

		 public override string ToString()
		 {
			  return this.GetType().Name + "[" + _encoder + "," + _radix + "]";
		 }

		 public override void Close()
		 {
			  _dataCache.close();
			  _groupCache.close();
			  if ( _trackerCache != null )
			  {
					_trackerCache.close();
			  }
			  if ( _collisionNodeIdCache != null )
			  {
					_collisionNodeIdCache.close();
			  }
			  if ( _collisionValues != null )
			  {
					_collisionValues.close();
			  }
		 }

		 public override MemoryStatsVisitor_Visitable MemoryEstimation( long numberOfNodes )
		 {
			  return new MemoryStatsVisitor_VisitableAnonymousInnerClass( this, numberOfNodes );
		 }

		 private class MemoryStatsVisitor_VisitableAnonymousInnerClass : MemoryStatsVisitor_Visitable
		 {
			 private readonly EncodingIdMapper _outerInstance;

			 private long _numberOfNodes;

			 public MemoryStatsVisitor_VisitableAnonymousInnerClass( EncodingIdMapper outerInstance, long numberOfNodes )
			 {
				 this.outerInstance = outerInstance;
				 this._numberOfNodes = numberOfNodes;
			 }

			 public void acceptMemoryStatsVisitor( MemoryStatsVisitor visitor )
			 {
				  int trackerSize = _numberOfNodes > IntTracker.MaxId ? BigIdTracker.SIZE : IntTracker.Size;
				  visitor.OffHeapUsage( _numberOfNodes * ( Long.BYTES + trackerSize ) );
			 }
		 }

		 public override LongIterator LeftOverDuplicateNodesIds()
		 {
			  if ( _numberOfCollisions == 0 )
			  {
					return ImmutableEmptyLongIterator.INSTANCE;
			  }

			  // Scans duplicate marks in tracker cache. There is no bit left in dataCache to store this bit so we use
			  // the tracker cache as if each index into it was the node id.
			  return new PrimitiveLongBaseIteratorAnonymousInnerClass( this );
		 }

		 private class PrimitiveLongBaseIteratorAnonymousInnerClass : PrimitiveLongCollections.PrimitiveLongBaseIterator
		 {
			 private readonly EncodingIdMapper _outerInstance;

			 public PrimitiveLongBaseIteratorAnonymousInnerClass( EncodingIdMapper outerInstance )
			 {
				 this.outerInstance = outerInstance;
			 }

			 private long nodeId;

			 protected internal override bool fetchNext()
			 {
				  while ( nodeId <= _outerInstance.highestSetIndex )
				  {
						long candidate = nodeId++;
						if ( _outerInstance.trackerCache.isMarkedAsDuplicate( candidate ) )
						{
							 return next( candidate );
						}
				  }
				  return false;
			 }
		 }
	}

}